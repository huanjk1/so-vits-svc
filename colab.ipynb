{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huanjk1/so-vits-svc/blob/main/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHaw6hGEa_Nk"
      },
      "source": [
        "# **Initialize environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gQcIZ8RsOkn"
      },
      "outputs": [],
      "source": [
        "#@title Connect to colab runtime and check GPU\n",
        "\n",
        "#@markdown # Connect to colab runtime and check GPU\n",
        "\n",
        "#@markdown\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YUGpYrXhMck"
      },
      "outputs": [],
      "source": [
        "#@title Clone repository and install requirements\n",
        "\n",
        "#@markdown # Clone repository and install requirements\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### After the execution is completed, the runtime will **automatically restart**\n",
        "\n",
        "#@markdown\n",
        "\n",
        "!git clone https://github.com/huanjk1/so-vits-svc -b 4.1-Stable\n",
        "%cd /content/so-vits-svc\n",
        "%pip install --upgrade pip setuptools jedi\n",
        "%pip install -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121\n",
        "exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmUkpUmfn_Hs"
      },
      "outputs": [],
      "source": [
        "#@title Mount google drive and select which directories to sync with google drive\n",
        "\n",
        "#@markdown # Mount google drive and select which directories to sync with google drive\n",
        "\n",
        "#@markdown\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "#@markdown Directory to store **necessary files**, dont miss the slash at the endðŸ‘‡.\n",
        "sovits_data_dir = \"/content/drive/MyDrive/mo/\"  #@param {type:\"string\"}\n",
        "#@markdown By default it will create a `sovits4data/` folder in your google drive.\n",
        "RAW_DIR = sovits_data_dir + \"raw/\"\n",
        "RESULTS_DIR = sovits_data_dir + \"results/\"\n",
        "FILELISTS_DIR = sovits_data_dir + \"filelists/\"\n",
        "CONFIGS_DIR = sovits_data_dir + \"configs/\"\n",
        "LOGS_DIR = sovits_data_dir + \"logs/44k/\"\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### These folders will be synced with your google drvie\n",
        "\n",
        "#@markdownã€€### **Strongly recommend to check all.**\n",
        "\n",
        "#@markdown Sync **input audios** and **output audios**\n",
        "sync_raw_and_results = True  #@param {type:\"boolean\"}\n",
        "if sync_raw_and_results:\n",
        "  !mkdir -p {RAW_DIR}\n",
        "  !mkdir -p {RESULTS_DIR}\n",
        "  !rm -rf /content/so-vits-svc/raw\n",
        "  !rm -rf /content/so-vits-svc/results\n",
        "  !ln -s {RAW_DIR} /content/so-vits-svc/raw\n",
        "  !ln -s {RESULTS_DIR} /content/so-vits-svc/results\n",
        "\n",
        "#@markdown Sync **config** and **models**\n",
        "sync_configs_and_logs = True  #@param {type:\"boolean\"}\n",
        "if sync_configs_and_logs:\n",
        "  !mkdir -p {FILELISTS_DIR}\n",
        "  !mkdir -p {CONFIGS_DIR}\n",
        "  !mkdir -p {LOGS_DIR}\n",
        "  !rm -rf /content/so-vits-svc/filelists\n",
        "  !rm -rf /content/so-vits-svc/configs\n",
        "  !rm -rf /content/so-vits-svc/logs/44k\n",
        "  !ln -s {FILELISTS_DIR} /content/so-vits-svc/filelists\n",
        "  !ln -s {CONFIGS_DIR} /content/so-vits-svc/configs\n",
        "  !ln -s {LOGS_DIR} /content/so-vits-svc/logs/44k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_PMPCN6wvgZ"
      },
      "outputs": [],
      "source": [
        "#@title Get pretrained model(Optional but strongly recommend).\n",
        "\n",
        "#@markdown # Get pretrained model(Optional but strongly recommend).\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown - Pre-trained model files: `G_0.pth` `D_0.pth`\n",
        "#@markdown   - Place them under /sovits4data/logs/44k/ in your google drive manualy\n",
        "\n",
        "#@markdown Get them from svc-develop-team(TBD) or anywhere else.\n",
        "\n",
        "#@markdown Although the pretrained model generally does not cause any copyright problems, please pay attention to it. For example, ask the author in advance, or the author has indicated the feasible use in the description clearly.\n",
        "\n",
        "download_pretrained_model = True #@param {type:\"boolean\"}\n",
        "D_0_URL = \"https://huggingface.co/datasets/ms903/sovits4.0-768vec-layer12/resolve/main/vol_emb/clean_D_320000.pth\" #@param [\"https://huggingface.co/datasets/ms903/sovits4.0-768vec-layer12/resolve/main/sovits_768l12_pre_large_320k/clean_D_320000.pth\", \"https://huggingface.co/1asbgdh/sovits4.0-volemb-vec768/resolve/main/clean_D_320000.pth\", \"https://huggingface.co/datasets/ms903/sovits4.0-768vec-layer12/resolve/main/vol_emb/clean_D_320000.pth\"] {allow-input: true}\n",
        "G_0_URL = \"https://huggingface.co/datasets/ms903/sovits4.0-768vec-layer12/resolve/main/vol_emb/clean_G_320000.pth\" #@param [\"https://huggingface.co/datasets/ms903/sovits4.0-768vec-layer12/resolve/main/sovits_768l12_pre_large_320k/clean_G_320000.pth\", \"https://huggingface.co/1asbgdh/sovits4.0-volemb-vec768/resolve/main/clean_G_320000.pth\", \"https://huggingface.co/datasets/ms903/sovits4.0-768vec-layer12/resolve/main/vol_emb/clean_G_320000.pth\"] {allow-input: true}\n",
        "\n",
        "download_pretrained_diffusion_model = True #@param {type:\"boolean\"}\n",
        "diff_model_URL = \"https://huggingface.co/datasets/ms903/Diff-SVC-refactor-pre-trained-model/resolve/main/fix_pitch_add_vctk_600k/model_0.pt\" #@param {type:\"string\"}\n",
        "\n",
        "%cd /content/so-vits-svc\n",
        "\n",
        "if download_pretrained_model:\n",
        "    !curl -L {D_0_URL} -o logs/44k/D_0.pth\n",
        "    !md5sum logs/44k/D_0.pth\n",
        "    !curl -L {G_0_URL} -o logs/44k/G_0.pth\n",
        "    !md5sum logs/44k/G_0.pth\n",
        "\n",
        "if download_pretrained_diffusion_model:\n",
        "    !mkdir -p logs/44k/diffusion\n",
        "    !curl -L {diff_model_URL} -o logs/44k/diffusion/model_0.pt\n",
        "    !md5sum logs/44k/diffusion/model_0.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1qadJBFehMo"
      },
      "source": [
        "# **Dataset preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBlju6Q3lSM6"
      },
      "source": [
        "Pack and upload your raw dataset(dataset_raw/) to your google drive.\n",
        "\n",
        "Makesure the file structure in your zip file looks like this:\n",
        "\n",
        "```\n",
        "YourZIPforSingleSpeakers.zip\n",
        "â””â”€â”€â”€speaker\n",
        "    â”œâ”€â”€â”€xxx1-xxx1.wav\n",
        "    â”œâ”€â”€â”€...\n",
        "    â””â”€â”€â”€Lxx-0xx8.wav\n",
        "```\n",
        "\n",
        "```\n",
        "YourZIPforMultipleSpeakers.zip\n",
        "â”œâ”€â”€â”€speaker0\n",
        "â”‚   â”œâ”€â”€â”€xxx1-xxx1.wav\n",
        "â”‚   â”œâ”€â”€â”€...\n",
        "â”‚   â””â”€â”€â”€Lxx-0xx8.wav\n",
        "â””â”€â”€â”€speaker1\n",
        "    â”œâ”€â”€â”€xx2-0xxx2.wav\n",
        "    â”œâ”€â”€â”€...\n",
        "    â””â”€â”€â”€xxx7-xxx007.wav\n",
        "```\n",
        "\n",
        "**Even if there is only one speaker, a folder named `{speaker_name}` is needed.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U05CXlAipvJR"
      },
      "outputs": [],
      "source": [
        "#@title Get raw dataset from google drive\n",
        "\n",
        "#@markdown # Get raw dataset from google drive\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown Directory where **your zip file** located in, dont miss the slash at the endðŸ‘‡.\n",
        "sovits_data_dir = \"/content/drive/MyDrive/mo/\"  #@param {type:\"string\"}\n",
        "#@markdown Filename of **your zip file**, do NOT be \"dataset.zip\"\n",
        "zip_filename = \"mov4\"  #@param {type:\"string\"}\n",
        "ZIP_PATH = sovits_data_dir + zip_filename\n",
        "\n",
        "!unzip -od /content/so-vits-svc/dataset_raw {ZIP_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ThKTzYs5CfL"
      },
      "outputs": [],
      "source": [
        "#@title Resample to 44100Hz and mono\n",
        "\n",
        "#@markdown # Resample to 44100Hz and mono\n",
        "\n",
        "#@markdown\n",
        "\n",
        "%cd /content/so-vits-svc\n",
        "!python resample.py --skip_loudnorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svITReeL5N8K"
      },
      "outputs": [],
      "source": [
        "#@title Divide filelists and generate config.json\n",
        "\n",
        "#@markdown # Divide filelists and generate config.json\n",
        "\n",
        "#@markdown\n",
        "\n",
        "%cd /content/so-vits-svc\n",
        "\n",
        "speech_encoder = \"vec768l12\" #@param [\"vec768l12\", \"vec256l9\", \"hubertsoft\", \"whisper-ppg\", \"whisper-ppg-large\"]\n",
        "use_vol_aug = True #@param {type:\"boolean\"}\n",
        "vol_aug = \"--vol_aug\" if use_vol_aug else \"\"\n",
        "\n",
        "from pretrain.meta import download_dict\n",
        "download_dict = download_dict()\n",
        "\n",
        "url = download_dict[speech_encoder][\"url\"]\n",
        "output = download_dict[speech_encoder][\"output\"]\n",
        "\n",
        "import os\n",
        "if not os.path.exists(output):\n",
        "  !curl -L {url} -o {output}\n",
        "  !md5sum {output}\n",
        "\n",
        "!python preprocess_flist_config.py --speech_encoder={speech_encoder} {vol_aug}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHUXMi836DMe"
      },
      "outputs": [],
      "source": [
        "#@title Generate hubert and f0\n",
        "\n",
        "#@markdown # Generate hubert and f0\n",
        "\n",
        "#@markdown\n",
        "%cd /content/so-vits-svc\n",
        "\n",
        "f0_predictor = \"rmvpe\" #@param [\"crepe\", \"pm\", \"dio\", \"harvest\", \"rmvpe\", \"fcpe\"]\n",
        "use_diff = True #@param {type:\"boolean\"}\n",
        "\n",
        "import os\n",
        "if f0_predictor == \"rmvpe\" and not os.path.exists(\"./pretrain/rmvpe.pt\"):\n",
        "  !curl -L https://huggingface.co/datasets/ylzz1997/rmvpe_pretrain_model/resolve/main/rmvpe.pt -o pretrain/rmvpe.pt\n",
        "\n",
        "if f0_predictor == \"fcpe\" and not os.path.exists(\"./pretrain/fcpe.pt\"):\n",
        "  !curl -L https://huggingface.co/datasets/ylzz1997/rmvpe_pretrain_model/resolve/main/fcpe.pt -o pretrain/fcpe.pt\n",
        "\n",
        "\n",
        "diff_param = \"\"\n",
        "if use_diff:\n",
        "  diff_param = \"--use_diff\"\n",
        "\n",
        "  if not os.path.exists(\"./pretrain/nsf_hifigan/model.ckpt\"):\n",
        "    !curl -L https://github.com/openvpi/vocoders/releases/download/nsf-hifigan-44.1k-hop512-128bin-2024.02/nsf_hifigan_44.1k_hop512_128bin_2024.02.zip -o nsf_hifigan_44.1k_hop512_128bin_2024.02.zip\n",
        "    !unzip -o nsf_hifigan_44.1k_hop512_128bin_2024.02.zip\n",
        "    !rm -rf pretrain/nsf_hifigan\n",
        "    !mv -v /content/so-vits-svc/nsf_hifigan_44.1k_hop512_128bin_2024.02 pretrain/nsf_hifigan\n",
        "\n",
        "!python preprocess_hubert_f0.py --f0_predictor={f0_predictor} {diff_param}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wo4OTmTAUXgj"
      },
      "outputs": [],
      "source": [
        "#@title Save the preprocessed dataset to google drive\n",
        "\n",
        "#@markdown # Save the preprocessed dataset to google drive\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown You can save the dataset and related files to your google drive for the next training\n",
        "\n",
        "#@markdown **Directory for saving**, dont miss the slash at the endðŸ‘‡.\n",
        "sovits_data_dir = \"/content/drive/MyDrive/mo/\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown There will be a `dataset.zip` contained `dataset/` in your google drive, which is preprocessed data.\n",
        "\n",
        "!mkdir -p {sovits_data_dir}\n",
        "!zip -r dataset.zip /content/so-vits-svc/dataset\n",
        "!cp -vr dataset.zip \"{sovits_data_dir}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2G6v_6zblWK"
      },
      "outputs": [],
      "source": [
        "#@title Unzip preprocessed dataset from google drive directly if you have preprocessed already.\n",
        "\n",
        "#@markdown # Unzip preprocessed dataset from google drive directly if you have preprocessed already.\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown Directory where **your preprocessed dataset** located in, dont miss the slash at the endðŸ‘‡.\n",
        "sovits_data_dir = \"/content/drive/MyDrive/mo/\" #@param {type:\"string\"}\n",
        "CONFIG = sovits_data_dir + \"configs/\"\n",
        "FILELISTS = sovits_data_dir + \"filelists/\"\n",
        "DATASET = sovits_data_dir + \"dataset.zip\"\n",
        "\n",
        "!cp -vr {CONFIG} /content/so-vits-svc/\n",
        "!cp -vr {FILELISTS} /content/so-vits-svc/\n",
        "!unzip {DATASET} -d /"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENoH-pShel7w"
      },
      "source": [
        "# **Trainning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hEFFTCfZf57"
      },
      "outputs": [],
      "source": [
        "#@title Start training\n",
        "\n",
        "#@markdown # Start training\n",
        "\n",
        "#@markdown If you want to use pre-trained models, upload them to /sovits4data/logs/44k/ in your google drive manualy.\n",
        "\n",
        "#@markdown\n",
        "\n",
        "%cd /content/so-vits-svc\n",
        "\n",
        "#@markdown Whether to enable tensorboard\n",
        "tensorboard_on = True  #@param {type:\"boolean\"}\n",
        "\n",
        "if tensorboard_on:\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir logs/44k\n",
        "\n",
        "config_path = \"configs/config.json\"\n",
        "\n",
        "from pretrain.meta import get_speech_encoder\n",
        "url, output = get_speech_encoder(config_path)\n",
        "\n",
        "import os\n",
        "if not os.path.exists(output):\n",
        "  !curl -L {url} -o {output}\n",
        "\n",
        "!python train.py -c {config_path} -m 44k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZThaMxmIJgWy"
      },
      "outputs": [],
      "source": [
        "#@title Train cluster model (Optional)\n",
        "\n",
        "#@markdown # Train cluster model (Optional)\n",
        "\n",
        "#@markdown #### Details see [README.md#cluster-based-timbre-leakage-control](https://github.com/svc-develop-team/so-vits-svc#cluster-based-timbre-leakage-control)\n",
        "\n",
        "#@markdown\n",
        "\n",
        "%cd /content/so-vits-svc\n",
        "!python cluster/train_cluster.py --gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmI_0lX0TioG"
      },
      "outputs": [],
      "source": [
        "#@title Train index model (Optional)\n",
        "\n",
        "#@markdown # Train index model (Optional)\n",
        "\n",
        "#@markdown #### Details see [README.md#feature-retrieval](https://github.com/svc-develop-team/so-vits-svc#feature-retrieval)\n",
        "\n",
        "#@markdown\n",
        "\n",
        "%cd /content/so-vits-svc\n",
        "!python train_index.py -c configs/config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "or1BojAeTioG"
      },
      "outputs": [],
      "source": [
        "#@title Train diffusion model (Optional)\n",
        "\n",
        "#@markdown # Train diffusion model (Optional)\n",
        "\n",
        "#@markdown #### Details see [README.md#-about-shallow-diffusion](https://github.com/svc-develop-team/so-vits-svc#-about-shallow-diffusion)\n",
        "\n",
        "#@markdown\n",
        "\n",
        "%cd /content/so-vits-svc\n",
        "\n",
        "import os\n",
        "if not os.path.exists(\"./pretrain/nsf_hifigan/model\"):\n",
        "  !curl -L https://github.com/openvpi/vocoders/releases/download/nsf-hifigan-v1/nsf_hifigan_20221211.zip -o nsf_hifigan_20221211.zip\n",
        "  !unzip nsf_hifigan_20221211.zip\n",
        "  !rm -rf pretrain/nsf_hifigan\n",
        "  !mv -v nsf_hifigan pretrain\n",
        "\n",
        "#@markdown Whether to enable tensorboard\n",
        "tensorboard_on = True  #@param {type:\"boolean\"}\n",
        "\n",
        "if tensorboard_on:\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir logs/44k\n",
        "\n",
        "!python train_diff.py -c configs/diffusion.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7dmEmYKTioG"
      },
      "source": [
        "# keep colab alive\n",
        "Open the devtools and copy & paste to run the scrips.\n",
        "\n",
        "\n",
        "```JavaScript\n",
        "const ping = () => {\n",
        "  const btn = document.querySelector(\"colab-connect-button\");\n",
        "  const inner_btn = btn.shadowRoot.querySelector(\"#connect\");\n",
        "  if (inner_btn) {\n",
        "    inner_btn.click();\n",
        "    console.log(\"Clicked on connect button\");\n",
        "  } else {\n",
        "    console.log(\"connect button not found\");\n",
        "  }\n",
        "\n",
        "  const nextTime = 50000 + Math.random() * 10000;\n",
        "\n",
        "  setTimeout(ping, nextTime);\n",
        "};\n",
        "\n",
        "ping();\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCnbX-OT897k"
      },
      "source": [
        "# **Inference**\n",
        "### Upload wav files from this notebook\n",
        "### **OR**\n",
        "### Upload to `sovits4data/raw/` in your google drive manualy (should be faster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uz4llcOeTioH"
      },
      "outputs": [],
      "source": [
        "#title Download nsf_hifigan if you need it\n",
        "\n",
        "%cd /content/so-vits-svc\n",
        "!curl -L https://github.com/openvpi/vocoders/releases/download/nsf-hifigan-v1/nsf_hifigan_20221211.zip -o /content/so-vits-svc/nsf_hifigan_20221211.zip\n",
        "!unzip nsf_hifigan_20221211.zip\n",
        "!rm -rf pretrain/nsf_hifigan\n",
        "!mv -v nsf_hifigan pretrain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUsmGkgCMD_Q"
      },
      "outputs": [],
      "source": [
        "#@title Upload wav files, the filename should not contain any special symbols like `#` `$` `(` `)`\n",
        "\n",
        "#@markdown # Upload wav files, the filename should not contain any special symbols like `#` `$` `(` `)`\n",
        "\n",
        "#@markdown\n",
        "\n",
        "%cd /content/so-vits-svc\n",
        "%run wav_upload.py --type audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYnKuKTIj3z1"
      },
      "outputs": [],
      "source": [
        "#@title Start inference (and download)\n",
        "\n",
        "#@markdown # Start inference (and download)\n",
        "\n",
        "#@markdown Parameters see [README.MD#Inference](https://github.com/svc-develop-team/so-vits-svc#-inference)\n",
        "\n",
        "#@markdown\n",
        "\n",
        "wav_filename = \"YourWAVFile.wav\"  #@param {type:\"string\"}\n",
        "model_filename = \"G_210000.pth\"  #@param {type:\"string\"}\n",
        "model_path = \"/content/so-vits-svc/logs/44k/\" + model_filename\n",
        "speaker = \"YourSpeaker\"  #@param {type:\"string\"}\n",
        "trans = \"0\"  #@param {type:\"string\"}\n",
        "cluster_infer_ratio = \"0\"  #@param {type:\"string\"}\n",
        "auto_predict_f0 = False  #@param {type:\"boolean\"}\n",
        "apf = \"\"\n",
        "if auto_predict_f0:\n",
        "  apf = \" -a \"\n",
        "\n",
        "f0_predictor = \"crepe\" #@param [\"crepe\", \"pm\", \"dio\", \"harvest\", \"rmvpe\", \"fcpe\"]\n",
        "\n",
        "enhance = False  #@param {type:\"boolean\"}\n",
        "ehc = \"\"\n",
        "if enhance:\n",
        "  ehc = \" -eh \"\n",
        "#@markdown\n",
        "\n",
        "#@markdown Generally keep default:\n",
        "config_filename = \"config.json\"  #@param {type:\"string\"}\n",
        "config_path = \"/content/so-vits-svc/configs/\" + config_filename\n",
        "\n",
        "from pretrain.meta import get_speech_encoder\n",
        "url, output = get_speech_encoder(config_path)\n",
        "\n",
        "import os\n",
        "\n",
        "if f0_predictor == \"rmvpe\" and not os.path.exists(\"./pretrain/rmvpe.pt\"):\n",
        "  !curl -L https://huggingface.co/datasets/ylzz1997/rmvpe_pretrain_model/resolve/main/rmvpe.pt -o pretrain/rmvpe.pt\n",
        "\n",
        "if f0_predictor == \"fcpe\" and not os.path.exists(\"./pretrain/fcpe.pt\"):\n",
        "  !curl -L https://huggingface.co/datasets/ylzz1997/rmvpe_pretrain_model/resolve/main/fcpe.pt -o pretrain/fcpe.pt\n",
        "\n",
        "if not os.path.exists(output):\n",
        "  !curl -L {url} -o {output}\n",
        "\n",
        "kmeans_filenname = \"kmeans_10000.pt\"  #@param {type:\"string\"}\n",
        "kmeans_path = \"/content/so-vits-svc/logs/44k/\" + kmeans_filenname\n",
        "slice_db = \"-40\"  #@param {type:\"string\"}\n",
        "wav_format = \"flac\"  #@param {type:\"string\"}\n",
        "\n",
        "key = \"auto\" if auto_predict_f0 else f\"{trans}key\"\n",
        "cluster_name = \"\" if cluster_infer_ratio == \"0\" else f\"_{cluster_infer_ratio}\"\n",
        "isdiffusion = \"sovits\"\n",
        "wav_output = f\"/content/so-vits-svc/results/{wav_filename}_{key}_{speaker}{cluster_name}_{isdiffusion}_{f0_predictor}.{wav_format}\"\n",
        "\n",
        "%cd /content/so-vits-svc\n",
        "!python inference_main.py -n {wav_filename} -m {model_path} -s {speaker} -t {trans} -cr {cluster_infer_ratio} -c {config_path} -cm {kmeans_path} -sd {slice_db} -wf {wav_format} {apf} --f0_predictor={f0_predictor} {ehc}\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown If you dont want to download from here, uncheck this.\n",
        "download_after_inference = True  #@param {type:\"boolean\"}\n",
        "\n",
        "if download_after_inference:\n",
        "  from google.colab import files\n",
        "  files.download(wav_output)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}